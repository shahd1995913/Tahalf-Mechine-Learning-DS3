{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/Tahalf-Mechine-Learning-DS3/blob/main/SVM/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf71dde",
      "metadata": {
        "id": "ebf71dde"
      },
      "source": [
        "# **SVM üë®üèª‚Äçüíª**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a076855",
      "metadata": {
        "id": "6a076855"
      },
      "source": [
        "### From Scratch Implementation ü§î\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89dd7ad6",
      "metadata": {
        "id": "89dd7ad6",
        "outputId": "2dbbc72a-3d9d-4d64-e212-39a16976c284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: progressbar in c:\\users\\asset\\anaconda3\\lib\\site-packages (2.5)\n",
            "Requirement already satisfied: cvxopt in c:\\users\\asset\\anaconda3\\lib\\site-packages (1.2.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install progressbar\n",
        "!pip install cvxopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a4f401",
      "metadata": {
        "id": "f9a4f401"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import math\n",
        "import progressbar\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cmx\n",
        "import matplotlib.colors as colors\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "bar_widgets = [\n",
        "    'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
        "    ' ', progressbar.ETA()\n",
        "]\n",
        "\n",
        "\n",
        "def standardize(X):\n",
        "    \"\"\" Standardize the dataset X \"\"\"\n",
        "    X_std = X\n",
        "    mean = X.mean(axis=0)\n",
        "    std = X.std(axis=0)\n",
        "    for col in range(np.shape(X)[1]):\n",
        "        if std[col]:\n",
        "            X_std[:, col] = (X_std[:, col] - mean[col]) / std[col]\n",
        "    # X_std = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    return X_std\n",
        "\n",
        "def normalize(X, axis=-1, order=2):\n",
        "    \"\"\" Normalize the dataset X \"\"\"\n",
        "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
        "    l2[l2 == 0] = 1\n",
        "    return X / np.expand_dims(l2, axis)\n",
        "\n",
        "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
        "    \"\"\" Split the data into train and test sets \"\"\"\n",
        "    if shuffle:\n",
        "        X, y = shuffle_data(X, y, seed)\n",
        "    # Split the training data from test data in the ratio specified in\n",
        "    # test_size\n",
        "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
        "    X_train, X_test = X[:split_i], X[split_i:]\n",
        "    y_train, y_test = y[:split_i], y[split_i:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def shuffle_data(X, y, seed=None):\n",
        "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "    idx = np.arange(X.shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    return X[idx], y[idx]\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
        "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "def calculate_covariance_matrix(X, Y=None):\n",
        "    \"\"\" Calculate the covariance matrix for the dataset X \"\"\"\n",
        "    if Y is None:\n",
        "        Y = X\n",
        "    n_samples = np.shape(X)[0]\n",
        "    covariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n",
        "\n",
        "    return np.array(covariance_matrix, dtype=float)\n",
        " \n",
        "\n",
        "def calculate_correlation_matrix(X, Y=None):\n",
        "    \"\"\" Calculate the correlation matrix for the dataset X \"\"\"\n",
        "    if Y is None:\n",
        "        Y = X\n",
        "    n_samples = np.shape(X)[0]\n",
        "    covariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\n",
        "    std_dev_X = np.expand_dims(calculate_std_dev(X), 1)\n",
        "    std_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\n",
        "    correlation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n",
        "\n",
        "    return np.array(correlation_matrix, dtype=float)\n",
        "\n",
        "class Plot():\n",
        "    def __init__(self): \n",
        "        self.cmap = plt.get_cmap('viridis')\n",
        "\n",
        "    def _transform(self, X, dim):\n",
        "        covariance = calculate_covariance_matrix(X)\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
        "        # Sort eigenvalues and eigenvector by largest eigenvalues\n",
        "        idx = eigenvalues.argsort()[::-1]\n",
        "        eigenvalues = eigenvalues[idx][:dim]\n",
        "        eigenvectors = np.atleast_1d(eigenvectors[:, idx])[:, :dim]\n",
        "        # Project the data onto principal components\n",
        "        X_transformed = X.dot(eigenvectors)\n",
        "\n",
        "        return X_transformed\n",
        "\n",
        "\n",
        "    def plot_regression(self, lines, title, axis_labels=None, mse=None, scatter=None, legend={\"type\": \"lines\", \"loc\": \"lower right\"}):\n",
        "        \n",
        "        if scatter:\n",
        "            scatter_plots = scatter_labels = []\n",
        "            for s in scatter:\n",
        "                scatter_plots += [plt.scatter(s[\"x\"], s[\"y\"], color=s[\"color\"], s=s[\"size\"])]\n",
        "                scatter_labels += [s[\"label\"]]\n",
        "            scatter_plots = tuple(scatter_plots)\n",
        "            scatter_labels = tuple(scatter_labels)\n",
        "\n",
        "        for l in lines:\n",
        "            li = plt.plot(l[\"x\"], l[\"y\"], color=s[\"color\"], linewidth=l[\"width\"], label=l[\"label\"])\n",
        "\n",
        "        if mse:\n",
        "            plt.suptitle(title)\n",
        "            plt.title(\"MSE: %.2f\" % mse, fontsize=10)\n",
        "        else:\n",
        "            plt.title(title)\n",
        "\n",
        "        if axis_labels:\n",
        "            plt.xlabel(axis_labels[\"x\"])\n",
        "            plt.ylabel(axis_labels[\"y\"])\n",
        "\n",
        "        if legend[\"type\"] == \"lines\":\n",
        "            plt.legend(loc=\"lower_left\")\n",
        "        elif legend[\"type\"] == \"scatter\" and scatter:\n",
        "            plt.legend(scatter_plots, scatter_labels, loc=legend[\"loc\"])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # Plot the dataset X and the corresponding labels y in 2D using PCA.\n",
        "    def plot_in_2d(self, X, y=None, title=None, accuracy=None, legend_labels=None):\n",
        "        X_transformed = self._transform(X, dim=2)\n",
        "        x1 = X_transformed[:, 0]\n",
        "        x2 = X_transformed[:, 1]\n",
        "        class_distr = []\n",
        "\n",
        "        y = np.array(y).astype(int)\n",
        "\n",
        "        colors = [self.cmap(i) for i in np.linspace(0, 1, len(np.unique(y)))]\n",
        "\n",
        "        # Plot the different class distributions\n",
        "        for i, l in enumerate(np.unique(y)):\n",
        "            _x1 = x1[y == l]\n",
        "            _x2 = x2[y == l]\n",
        "            _y = y[y == l]\n",
        "            class_distr.append(plt.scatter(_x1, _x2, color=colors[i]))\n",
        "\n",
        "        # Plot legend\n",
        "        if not legend_labels is None: \n",
        "            plt.legend(class_distr, legend_labels, loc=1)\n",
        "\n",
        "        # Plot title\n",
        "        if title:\n",
        "            if accuracy:\n",
        "                perc = 100 * accuracy\n",
        "                plt.suptitle(title)\n",
        "                plt.title(\"Accuracy: %.1f%%\" % perc, fontsize=10)\n",
        "            else:\n",
        "                plt.title(title)\n",
        "\n",
        "        # Axis labels\n",
        "        plt.xlabel('Principal Component 1')\n",
        "        plt.ylabel('Principal Component 2')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # Plot the dataset X and the corresponding labels y in 3D using PCA.\n",
        "    def plot_in_3d(self, X, y=None):\n",
        "        X_transformed = self._transform(X, dim=3)\n",
        "        x1 = X_transformed[:, 0]\n",
        "        x2 = X_transformed[:, 1]\n",
        "        x3 = X_transformed[:, 2]\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.scatter(x1, x2, x3, c=y)\n",
        "        plt.show()\n",
        "\n",
        "class Sigmoid():\n",
        "    def __call__(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def gradient(self, x):\n",
        "        return self.__call__(x) * (1 - self.__call__(x))\n",
        "\n",
        "def make_diagonal(x):\n",
        "    \"\"\" Converts a vector into an diagonal matrix \"\"\"\n",
        "    m = np.zeros((len(x), len(x)))\n",
        "    for i in range(len(m[0])):\n",
        "        m[i, i] = x[i]\n",
        "    return m\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f7cbfe",
      "metadata": {
        "id": "18f7cbfe"
      },
      "outputs": [],
      "source": [
        "# importing some kernels\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def linear_kernel(**kwargs):\n",
        "    def f(x1, x2):\n",
        "        return np.inner(x1, x2)\n",
        "    return f\n",
        "\n",
        "\n",
        "def polynomial_kernel(power, coef, **kwargs):\n",
        "    def f(x1, x2):\n",
        "        return (np.inner(x1, x2) + coef)**power\n",
        "    return f\n",
        "\n",
        "\n",
        "def rbf_kernel(gamma, **kwargs):\n",
        "    def f(x1, x2):\n",
        "        distance = np.linalg.norm(x1 - x2) ** 2\n",
        "        return np.exp(-gamma * distance)\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bade8e81",
      "metadata": {
        "id": "bade8e81"
      },
      "outputs": [],
      "source": [
        "import cvxopt\n",
        "\n",
        "# Hide cvxopt output\n",
        "cvxopt.solvers.options['show_progress'] = False\n",
        "\n",
        "class SupportVectorMachine(object):\n",
        "    \"\"\"The Support Vector Machine classifier.\n",
        "    Uses cvxopt to solve the quadratic optimization problem.\n",
        "    Parameters:\n",
        "    -----------\n",
        "    C: float\n",
        "        Penalty term.\n",
        "    kernel: function\n",
        "        Kernel function. Can be either polynomial, rbf or linear.\n",
        "    power: int\n",
        "        The degree of the polynomial kernel. Will be ignored by the other\n",
        "        kernel functions.\n",
        "    gamma: float\n",
        "        Used in the rbf kernel function.\n",
        "    coef: float\n",
        "        Bias term used in the polynomial kernel function.\n",
        "    \"\"\"\n",
        "    def __init__(self, C=1, kernel=rbf_kernel, power=4, gamma=None, coef=4):\n",
        "        self.C = C\n",
        "        self.kernel = kernel\n",
        "        self.power = power\n",
        "        self.gamma = gamma\n",
        "        self.coef = coef\n",
        "        self.lagr_multipliers = None\n",
        "        self.support_vectors = None\n",
        "        self.support_vector_labels = None\n",
        "        self.intercept = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        n_samples, n_features = np.shape(X)\n",
        "\n",
        "        # Set gamma to 1/n_features by default\n",
        "        if not self.gamma:\n",
        "            self.gamma = 1 / n_features\n",
        "\n",
        "        # Initialize kernel method with parameters\n",
        "        self.kernel = self.kernel(\n",
        "            power=self.power,\n",
        "            gamma=self.gamma,\n",
        "            coef=self.coef)\n",
        "\n",
        "        # Calculate kernel matrix\n",
        "        kernel_matrix = np.zeros((n_samples, n_samples))\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                kernel_matrix[i, j] = self.kernel(X[i], X[j])\n",
        "\n",
        "        # Define the quadratic optimization problem\n",
        "        P = cvxopt.matrix(np.outer(y, y) * kernel_matrix, tc='d')\n",
        "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
        "        A = cvxopt.matrix(y, (1, n_samples), tc='d')\n",
        "        b = cvxopt.matrix(0, tc='d')\n",
        "\n",
        "        if not self.C:\n",
        "            G = cvxopt.matrix(np.identity(n_samples) * -1)\n",
        "            h = cvxopt.matrix(np.zeros(n_samples))\n",
        "        else:\n",
        "            G_max = np.identity(n_samples) * -1\n",
        "            G_min = np.identity(n_samples)\n",
        "            G = cvxopt.matrix(np.vstack((G_max, G_min)))\n",
        "            h_max = cvxopt.matrix(np.zeros(n_samples))\n",
        "            h_min = cvxopt.matrix(np.ones(n_samples) * self.C)\n",
        "            h = cvxopt.matrix(np.vstack((h_max, h_min)))\n",
        "\n",
        "        # Solve the quadratic optimization problem using cvxopt\n",
        "        minimization = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "        # Lagrange multipliers\n",
        "        lagr_mult = np.ravel(minimization['x'])\n",
        "\n",
        "        # Extract support vectors\n",
        "        # Get indexes of non-zero lagr. multipiers\n",
        "        idx = lagr_mult > 1e-7\n",
        "        # Get the corresponding lagr. multipliers\n",
        "        self.lagr_multipliers = lagr_mult[idx]\n",
        "        # Get the samples that will act as support vectors\n",
        "        self.support_vectors = X[idx]\n",
        "        # Get the corresponding labels\n",
        "        self.support_vector_labels = y[idx]\n",
        "\n",
        "        # Calculate intercept with first support vector\n",
        "        self.intercept = self.support_vector_labels[0]\n",
        "        for i in range(len(self.lagr_multipliers)):\n",
        "            self.intercept -= self.lagr_multipliers[i] * self.support_vector_labels[\n",
        "                i] * self.kernel(self.support_vectors[i], self.support_vectors[0])\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        # Iterate through list of samples and make predictions\n",
        "        for sample in X:\n",
        "            prediction = 0\n",
        "            # Determine the label of the sample by the support vectors\n",
        "            for i in range(len(self.lagr_multipliers)):\n",
        "                prediction += self.lagr_multipliers[i] * self.support_vector_labels[\n",
        "                    i] * self.kernel(self.support_vectors[i], sample)\n",
        "            prediction += self.intercept\n",
        "            y_pred.append(np.sign(prediction))\n",
        "        return np.array(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba63398",
      "metadata": {
        "id": "9ba63398",
        "outputId": "fb7e4a49-3781-4224-9094-e2f06caeed8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9696969696969697\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from __future__ import division, print_function\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "# Import helper functions\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = datasets.load_iris()\n",
        "    X = normalize(data.data[data.target != 0])\n",
        "    y = data.target[data.target != 0]\n",
        "    y[y == 1] = -1\n",
        "    y[y == 2] = 1\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "    clf = SupportVectorMachine(kernel=polynomial_kernel, power=4, coef=1)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print (\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Reduce dimension to two using PCA and plot the results\n",
        "    Plot().plot_in_2d(X_test, y_pred, title=\"Support Vector Machine\", accuracy=accuracy)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffab1690",
      "metadata": {
        "id": "ffab1690"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}