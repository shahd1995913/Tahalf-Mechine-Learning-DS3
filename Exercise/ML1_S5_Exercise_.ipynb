{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/Tahalf-Mechine-Learning-DS3/blob/main/Exercise/ML1_S5_Exercise_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzVjwL7dxy4p"
      },
      "source": [
        "# ML1-S3 (K Nearest Neighbor (`KNN`) Algorithm)üë®üèª‚Äçüíª\n",
        "---\n",
        "\n",
        "### Agenda\n",
        "- [Introduction](#Introduction)\n",
        "- [How does KNN Work?](#How)\n",
        "- [Model Representation](#Representation)\n",
        "- [Required Data Preparation](#Preparation)\n",
        "- [sklean Implementation](#Implementation)\n",
        "- [Implementation from scratch](#scratch)\n",
        "- [Compaire models](#Compaire)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBhcQp5owWL8"
      },
      "source": [
        "## <a id='Introduction'></a> `Introduction`\n",
        "---\n",
        "**K Nearest Neighbor** algorithm falls under the `Supervised` Learning category and is used for **classification** (most commonly) and **regression**. It is a versatile algorithm also used for imputing missing values and resampling datasets. As the name (K Nearest Neighbor) suggests it considers K Nearest Neighbors (Data points) to predict the class or continuous value for the new Datapoint.\n",
        "<img src=https://machinelearningknowledge.ai/wp-content/uploads/2018/08/KNN-Classification.gif width= 500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEKS7-SmwZXT"
      },
      "source": [
        "**The algorithm‚Äôs learning is**:\n",
        "\n",
        "---\n",
        "1. Instance-based learning: Here we do not learn weights from training data to predict output (as in model-based algorithms) but use entire training instances to predict output for unseen data.\n",
        "\n",
        "\n",
        "2. Lazy Learning: Model is not learned using training data prior and the learning process is postponed to a time when prediction is requested on the new instance.\n",
        "\n",
        "\n",
        "3. Non -Parametric: In KNN, there is no predefined form of the mapping function.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1XbIunDwktG"
      },
      "source": [
        "## <a id='How'></a> `How does KNN Work?`\n",
        "---\n",
        "üëâ**Principle**:\n",
        "\n",
        "Consider the following figure. Let us say we have plotted data points from our training set on a two-dimensional feature space. As shown, we have a total of 6 data points (3 red and 3 blue). \n",
        "\n",
        "Red data points belong to `class1` and blue data points belong to `class2`. \n",
        "\n",
        "And yellow data point in a feature space represents the new point for which a class is to be predicted. Obviously, we say it belongs to ‚Äòclass1‚Äô (red points)\n",
        "\n",
        "**Why?** ü§î‚û® Because its nearest neighbors belong to that class!\n",
        "<img src=https://editor.analyticsvidhya.com/uploads/17303KNN%20working.png width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBHI524w0EL8"
      },
      "source": [
        "Yes, this is the principle behind K Nearest Neighbors. Here, nearest neighbors are those data points that have minimum distance in feature space from our new data point. And K is the number of such data points we consider in our implementation of the algorithm. Therefore, distance metric and K value are two important considerations while using the KNN algorithm. Euclidean distance is the most popular distance metric. You can also use Hamming distance, Manhattan distance, Minkowski distance as per your need. For predicting class/ continuous value for a new data point, it considers all the data points in the training dataset. Finds new data point‚Äôs ‚ÄòK‚Äô Nearest Neighbors (Data points) from feature space and their class labels or continuous values.\n",
        "\n",
        "Then:\n",
        "\n",
        "- For classification: A class label assigned to the majority of K Nearest Neighbors from the training dataset is considered as a predicted class for the new data point.\n",
        "\n",
        "- For regression: Mean or median of continuous values assigned to K Nearest Neighbors from training dataset is a predicted continuous value for our new data point\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaDQkdkI1HyV"
      },
      "source": [
        "## <a id='Representation'></a> `Model Representation`\n",
        "--- \n",
        "\n",
        "Here, we do not learn weights and store them, instead, the entire training dataset is stored in the memory. Therefore, model representation for KNN is the entire training dataset.\n",
        "\n",
        "### How to choose the value for K?** ü§î\n",
        "---\n",
        "\n",
        "**K is a crucial parameter in the KNN algorithm. Some suggestions for choosing K Value are**:\n",
        "\n",
        "1. Using error curves: The figure below shows error curves for different values of K for training and test data.\n",
        "\n",
        "    At low K values, there is overfitting of data/high variance. Therefore test error is high and train error is low. At K=1 in train data, the error is always zero, because the nearest neighbor to that point is that point itself. Therefore though training error is low test error is high at lower K values. This is called overfitting. As we increase the value for K, the test error is reduced.\n",
        "\n",
        "    But after a certain K value, bias/ underfitting is introduced and test error goes high. So we can say initially test data error is high(due to variance) then it goes low and stabilizes and with further increase in K value, it again increases(due to bias). The K value when test error stabilizes and is low is considered as optimal value for K. From the above error curve we can choose K=8 for our KNN algorithm implementation.\n",
        "\n",
        "    <img src=https://editor.analyticsvidhya.com/uploads/47280kvalue.png width=400>\n",
        "\n",
        "\n",
        "2. Also, domain knowledge is very useful in choosing the K value.\n",
        "\n",
        "3. K value should be odd while considering binary(two-class) classification.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53oC1RDl1cRJ"
      },
      "source": [
        "## <a id='Preparation'></a> `Required Data Preparation`\n",
        "---\n",
        "1. Data Scaling: To locate the data point in multidimensional feature space, it would be helpful if all features are on the same scale. Hence normalization or standardization of data will help.\n",
        "\n",
        "2. Dimensionality Reduction: KNN may not work well if there are too many features. Hence dimensionality reduction techniques like feature selection, principal component analysis can be implemented.\n",
        "\n",
        "3. Missing value treatment: If out of M features one feature data is missing for a particular example in the training set then we cannot locate or calculate distance from that point. Therefore deleting that row or imputation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvlR5OfA1lbd"
      },
      "source": [
        "## <a id='Implementation'></a> `sklean Implementation`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62uWhHwx1u2q"
      },
      "outputs": [],
      "source": [
        "#First, let‚Äôs import all required libraries.\n",
        "#============================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri5NCJ8u1wDT"
      },
      "source": [
        "After loading important libraries, we create our data using sklearn.datasets with 200 samples, 8 features, and 2 classes. Then data is split into the train(80%) and test(20%) data and scaled using StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEqfGKRQ1yCn",
        "outputId": "0a99e02a-f695-4896-f711-02ca2f39c724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, 8)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X,Y=make_classification(n_samples= 200,n_features=8,n_informative=8,n_redundant=0,n_repeated=0,n_classes=2,random_state=14)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, Y, test_size= 0.2,random_state=32)\n",
        "sc= StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train= sc.transform(X_train)\n",
        "sc.fit(X_test)\n",
        "X_test= sc.transform(X_test)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZxDaCZQ15Nq"
      },
      "source": [
        "For choosing the K value, we use error curves and K value with optimal variance, and bias error is chosen as K value for prediction purposes. With the error curve plotted below, we choose K=7 for the prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "b97eXTO6134F",
        "outputId": "9d182fa9-b97b-404a-b2a1-bfb4a65f09fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1a361118040>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 2: Find the value for K\n",
        "#====================================\n",
        "error1= []\n",
        "error2= []\n",
        "for k in range(1,15):\n",
        "    knn= KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train,y_train)\n",
        "    y_pred1= knn.predict(X_train)\n",
        "    error1.append(np.mean(y_train!= y_pred1))\n",
        "    y_pred2= knn.predict(X_test)\n",
        "    error2.append(np.mean(y_test!= y_pred2))\n",
        "# plt.figure(figsize(10,5))\n",
        "plt.plot(range(1,15),error1,label=\"train\")\n",
        "plt.plot(range(1,15),error2,label=\"test\")\n",
        "plt.xlabel('k Value')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE0MaFwN2AER"
      },
      "source": [
        "In step 2, we have chosen the K value to be 7. Now we substitute that value and get the accuracy score = 0.9 for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJwncSr22CTC",
        "outputId": "187a1022-38bc-4fd9-93c8-08622840733f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Step 3: Predict:\n",
        "#======================\n",
        "knn= KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred= knn.predict(X_test)\n",
        "metrics.accuracy_score(y_test,y_pred) == 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqxCimH42DNV"
      },
      "source": [
        "## <a id='scratch'></a> `Implementation from scratch`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTdM5lMRfKZe"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "#======================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Loading the Data\n",
        "iris= load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP1dTVFe3QID"
      },
      "outputs": [],
      "source": [
        "# Split X and Y\n",
        "#======================\n",
        "\n",
        "# Store features matrix in X\n",
        "X= iris.data\n",
        "#Store target vector in \n",
        "Y= iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, Y, test_size= 0.2,random_state=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-njvTec3Uib"
      },
      "source": [
        "### psudo code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o4WA3C-0PUH"
      },
      "source": [
        "K-nearest neighbors (KNN) algorithm uses ‚Äòfeature similarity‚Äô to predict the values of new datapoints which further means that the new data point will be assigned a value based on how closely it matches the points in the training set. We can understand its working with the help of following steps ‚àí\n",
        "\n",
        "- Step 1 ‚û® For implementing any algorithm, we need dataset. So during the first step of KNN, we must load the training as well as test data.\n",
        "\n",
        "- Step 2 ‚û® Next, we need to choose the value of K i.e. the nearest data points. K can be any integer.\n",
        "\n",
        "- Step 3 ‚û® For each point in the test data do the following:\n",
        "\n",
        "     * 3.1 ‚àí Calculate the distance between test data and each row of training data with the help of any of the method namely: Euclidean, Manhattan or Hamming distance. The most commonly used method to calculate distance is Euclidean.\n",
        "\n",
        "     * 3.2 ‚àí Now, based on the distance value, sort them in ascending order.\n",
        "\n",
        "     * 3.3 ‚àí Next, it will choose the top K rows from the sorted array.\n",
        "\n",
        "     * 3.4 ‚àí Now, it will assign a class to the test point based on most frequent class of these rows.\n",
        "\n",
        "- Step 4 ‚û® End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZEcrKy9fMt1"
      },
      "outputs": [],
      "source": [
        "class MyKNN():\n",
        "    def __init__(self,X,Y,dist):\n",
        "        self.X_train = X\n",
        "        self.Y_train = Y\n",
        "        self.metric = dist\n",
        "        \n",
        "    def euclidean_distance(self,p1,p2):\n",
        "        ''' this helper function calculates the euclidean distance between two given points '''\n",
        "        # the equation : sqrt(sum((x - y)^2))\n",
        "        dist = np.sqrt(np.sum( (p1-p2)**2 ))\n",
        "        return dist\n",
        "\n",
        "    def manhattan_distance(self,p1,p2):\n",
        "        ''' this helper function calculates the manhattan distance between two given points '''\n",
        "        # the equation : sum(|x - y|)\n",
        "        dist = sum(abs(p1-p2))\n",
        "        return dist\n",
        "\n",
        "    def calc_distance(self,p1,p2,metric=\"euclidean\"):\n",
        "        ''' This function calculate the distance between two numbers based on the given distance metric \n",
        "\n",
        "        INPUTS : \n",
        "        p1 : first point or vector (numpy array)\n",
        "        p2 : second point or vector (numpy array)\n",
        "        metric : the distance metric (string)\n",
        "        Returns : \n",
        "        distance value as a float number \n",
        "        '''\n",
        "\n",
        "        if metric == \"euclidean\":\n",
        "            dist = self.euclidean_distance(p1,p2)\n",
        "        elif metric ==\"manhattan\" :\n",
        "            dist = self.manhattan_distance(p1,p2)\n",
        "\n",
        "        else :\n",
        "            print(\"you have entered invalid metric value\")\n",
        "            print(\"please Choose between 'euclidean' and 'manhattan' \")\n",
        "            raise ValueError\n",
        "        return dist\n",
        "\n",
        "    def predict(self,X,y,X_,neighbors):\n",
        "        ''' This function KNN algorithm implementation \n",
        "        Inputs :\n",
        "            X : the training features vectors \n",
        "            y : the training targets/labels vectors \n",
        "            X_ : the input features we want to calculate the call for. \n",
        "            neighbors : the numbers of naghbors to calculate on. \n",
        "            metric : the distance metric we will calculate on \n",
        "\n",
        "        Output :\n",
        "            y_ : list of the predicted classes for our input \n",
        "        '''\n",
        "\n",
        "        #create output list\n",
        "        y_ = []\n",
        "\n",
        "        #iterate over inputs \n",
        "        for p in X_ :\n",
        "            dists = []\n",
        "            #calculate the distance between each point and the training data\n",
        "            for px in X:\n",
        "                dist = self.calc_distance(p,px,metric=self.metric)\n",
        "                dists.append(dist)\n",
        "            #get the minimun k distances    \n",
        "            mins = np.argsort(dists)[:neighbors]\n",
        "\n",
        "            # get the most repeated class\n",
        "            classes = [y[i] for i in mins]\n",
        "            pred = max(set(classes), key = classes.count)\n",
        "            y_.append(pred)\n",
        "        return y_\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRCSfZhAfSZO"
      },
      "outputs": [],
      "source": [
        "#create model and predict\n",
        "#==============================\n",
        "knn = MyKNN(X,Y,\"euclidean\")\n",
        "y_ = knn.predict(X_train,y_train,X_test,7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXIFEYVx905K",
        "outputId": "96677cf7-a598-4e07-8def-cb953f45eec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9666666666666667\n"
          ]
        }
      ],
      "source": [
        "# Accuracy\n",
        "#==========================\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "custom_model_score = accuracy_score(y_test,y_)\n",
        "\n",
        "print(custom_model_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYspSMZf-XZd"
      },
      "source": [
        "## <a id='Compaire'></a> `Compaire models`\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4mQc_fA-2gQ"
      },
      "source": [
        "#### sklearn model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-s1ntTlfTmQ"
      },
      "outputs": [],
      "source": [
        "# 7 kneighbors distance euclidean  \n",
        "knn= KNeighborsClassifier(n_neighbors=7,metric=\"euclidean\")\n",
        "# fit model\n",
        "knn.fit(X_train,y_train)\n",
        "#predict on test dataset\n",
        "y_pred= knn.predict(X_test)\n",
        "#get accuracy\n",
        "sklearn_model_score = metrics.accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWCI4Mo3fX1a",
        "outputId": "b41280db-b6cd-480a-c55c-de958d28503b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print (sklearn_model_score == custom_model_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aEg5px6fnp4"
      },
      "source": [
        "---\n",
        "# Homework\n",
        "---\n",
        "Tie break :\n",
        "\n",
        "\n",
        "Assume that you have selected the number of neighbours to be an even number, e.g., 2. For one of the neighbours, the suggested class is 1, and for the other neighbour the suggested class is 2. How would you break the tie? Write example pseudocode that does this."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML1_S5_Exercise .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}